\hypertarget{cha:dplyr}{%
\chapter{Data transformation}\label{cha:dplyr}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Tidy data is important, but it's not the end of the road. Often you
won't have quite the right variables, or your data might need a little
aggregation before you visualise it. This chapter will show you how to
solve these problems (and more!) with the \textbf{dplyr} package.
\index{Data!manipulating} \index{dplyr}
\index{Grammar!of data manipulation}

The goal of dplyr is to provide verbs (functions) that help you solve
the most common 95\% of data manipulation problems. dplyr is similar to
ggplot2, but instead of providing a grammar of graphics, it provides a
grammar of data manipulation. Like ggplot2, dplyr helps you not just by
giving you functions, but it also helps you think about data
manipulation. In particular, dplyr helps by constraining you: instead of
struggling to think about which of the thousands of functions that might
help, you can just pick from a handful that are design to be very likely
to be helpful. In this chapter you'll learn four of the most important
dplyr verbs:

\begin{itemize}
\tightlist
\item
  \texttt{filter()}
\item
  \texttt{mutate()}
\item
  \texttt{group\_by()} \& \texttt{summarise()}
\end{itemize}

These verbs are easy to learn because they all work the same way: they
take a data frame as the first argument, and return a modified data
frame. The other arguments control the details of the transformation,
and are always interpreted in the context of the data frame so you can
refer to variables directly. I'll also explain each in the same way:
I'll show you a motivating example using the \texttt{diamonds} data,
give you more details about how the function works, and finish up with
some exercises for you to practice your skills with.

You'll also learn how to create data transformation pipelines using
\texttt{\%\textgreater{}\%}. \texttt{\%\textgreater{}\%} plays a similar
role to \texttt{+} in ggplot2: it allows you to solve complex problems
by combining small pieces that are easily understood in isolation.

This chapter only scratches the surface of dplyr's capabilities but it
should be enough to help you with visualisation problems. You can learn
more by using the resources discussed at the end of the chapter.

\hypertarget{filter-observations}{%
\section{Filter observations}\label{filter-observations}}

It's common to only want to explore one part of a dataset. A great data
analysis strategy is to start with just one observation unit (one
person, one city, etc), and understand how it works before attempting to
generalise the conclusion to others. This is a great technique if you
ever feel overwhelmed by an analysis: zoom down to a small subset,
master it, and then zoom back out, to apply your conclusions to the full
dataset. \indexf{filter}

Filtering is also useful for extracting outliers. Generally, you don't
want to just throw outliers away, as they're often highly revealing, but
it's useful to think about partitioning the data into the common and the
unusual. You summarise the common to look at the broad trends; you
examine the outliers individually to see if you can figure out what's
going on.

For example, look at this plot that shows how the x and y dimensions of
the diamonds are related:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(diamonds, }\KeywordTok{aes}\NormalTok{(x, y)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bin2d}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/diamonds-x-y-1}
\end{figure}

There are around 50,000 points in this dataset: most of them lie along
the diagonal, but there are a handful of outliers. One clear set of
incorrect values are those diamonds with zero dimensions. We can use
\texttt{filter()} to pull them out:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{filter}\NormalTok{(diamonds, x }\OperatorTok{==}\StringTok{ }\DecValTok{0} \OperatorTok{|}\StringTok{ }\NormalTok{y }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}
\CommentTok{#> # A tibble: 8 x 10}
\CommentTok{#>   carat cut       color clari~ depth table price     x     y     z}
\CommentTok{#>   <dbl> <ord>     <ord> <ord>  <dbl> <dbl> <int> <dbl> <dbl> <dbl>}
\CommentTok{#> 1  1.07 Ideal     F     SI2     61.6  56.0  4954     0  6.62     0}
\CommentTok{#> 2  1.00 Very Good H     VS2     63.3  53.0  5139     0  0        0}
\CommentTok{#> 3  1.14 Fair      G     VS1     57.5  67.0  6381     0  0        0}
\CommentTok{#> 4  1.56 Ideal     G     VS2     62.2  54.0 12800     0  0        0}
\CommentTok{#> 5  1.20 Premium   D     VVS1    62.1  59.0 15686     0  0        0}
\CommentTok{#> 6  2.25 Premium   H     SI2     62.8  59.0 18034     0  0        0}
\CommentTok{#> # ... with 2 more rows}
\end{Highlighting}
\end{Shaded}

This is equivalent to the base R code
\texttt{diamonds{[}diamonds\$x\ ==\ 0\ \textbar{}\ diamonds\$y\ ==\ 0,\ {]}},
but is more concise because \texttt{filter()} knows to look for the bare
\texttt{x} in the data frame.

(If you've used \texttt{subset()} before, you'll notice that it has very
similar behaviour. The biggest difference is that \texttt{subset()} can
select both observations and variables, where in dplyr,
\texttt{filter()} works exclusively with observations and
\texttt{select()} with variables. There are some other subtle
differences, but the main advantage to using \texttt{filter()} is that
it behaves identically to the other dplyr verbs and it tends to be a bit
faster than \texttt{subset()}.)

In a real analysis, you'd look at the outliers in more detail to see if
you can find the root cause of the data quality problem. In this case,
we're just going to throw them out and focus on what remains. To save
some typing, we may provide multiple arguments to \texttt{filter()}
which combines them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds_ok <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(diamonds, x }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{, y }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{, y }\OperatorTok{<}\StringTok{ }\DecValTok{20}\NormalTok{)}
\KeywordTok{ggplot}\NormalTok{(diamonds_ok, }\KeywordTok{aes}\NormalTok{(x, y)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bin2d}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{slope =} \DecValTok{1}\NormalTok{, }\DataTypeTok{colour =} \StringTok{"white"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/diamonds-ok-1}
\end{figure}

This plot is now more informative - we can see a very strong
relationship between \texttt{x} and \texttt{y}. I've added the reference
line to make it clear that for most diamonds, \texttt{x} and \texttt{y}
are very similar. However, this plot still has problems:

\begin{itemize}
\item
  The plot is mostly empty, because most of the data lies along the
  diagonal.
\item
  There are some clear bivariate outliers, but it's hard to select them
  with a simple filter.
\end{itemize}

We'll solve both of these problem in the next section by adding a new
variable that's a transformation of x and y. But before we continue on
to that, let's talk more about the details of \texttt{filter()}.

\hypertarget{useful-tools}{%
\subsection{Useful tools}\label{useful-tools}}

The first argument to \texttt{filter()} is a data frame. The second and
subsequent arguments must be logical vectors: \texttt{filter()} selects
every row where all the logical expressions are \texttt{TRUE}. The
logical vectors must always be the same length as the data frame: if
not, you'll get an error. Typically you create the logical vector with
the comparison operators:

\begin{itemize}
\tightlist
\item
  \texttt{x\ ==\ y}: x and y are equal.
\item
  \texttt{x\ !=\ y}: x and y are not equal.
\item
  \texttt{x\ \%in\%\ c("a",\ "b",\ "c")}: \texttt{x} is one of the
  values in the right hand side.
\item
  \texttt{x\ \textgreater{}\ y}, \texttt{x\ \textgreater{}=\ y},
  \texttt{x\ \textless{}\ y}, \texttt{x\ \textless{}=\ y}: greater than,
  greater than or equal to, less than, less than or equal to.
\end{itemize}

And combine them with logical operators:

\begin{itemize}
\tightlist
\item
  \texttt{!x} (pronounced ``not x''), flips \texttt{TRUE} and
  \texttt{FALSE} so it keeps all the values where \texttt{x} is
  \texttt{FALSE}.
\item
  \texttt{x\ \&\ y}: \texttt{TRUE} if both \texttt{x} and \texttt{y} are
  \texttt{TRUE}.
\item
  \texttt{x\ \textbar{}\ y}: \texttt{TRUE} if either \texttt{x} or
  \texttt{y} (or both) are \texttt{TRUE}.
\item
  \texttt{xor(x,\ y)}: \texttt{TRUE} if either \texttt{x} or \texttt{y}
  are \texttt{TRUE}, but not both (exclusive or).
\end{itemize}

Most real queries involve some combination of both:

\begin{itemize}
\tightlist
\item
  Price less than \$500: \texttt{price\ \textless{}\ 500}
\item
  Size between 1 and 2 carats:
  \texttt{carat\ \textgreater{}=\ 1\ \&\ carat\ \textless{}\ 2}
\item
  Cut is ideal or premium:
  \texttt{cut\ ==\ "Premium"\ \textbar{}\ cut\ ==\ "Ideal"}, or
  \texttt{cut\ \%in\%\ c("Premium",\ "Ideal")} (note that R is case
  sensitive)
\item
  Worst colour, cut and clarity:
  \texttt{cut\ ==\ "Fair"\ \&\ color\ ==\ "J"\ \&\ clarity\ ==\ "SI2"}
\end{itemize}

You can also use functions in the filtering expression:

\begin{itemize}
\tightlist
\item
  Size is between 1 and 2 carats: \texttt{floor(carat)\ ==\ 1}
\item
  An average dimension greater than 3:
  \texttt{(x\ +\ y\ +\ z)\ /\ 3\ \textgreater{}\ 3}
\end{itemize}

This is useful for simple expressions, but as things get more
complicated it's better to create a new variable first so you can check
that you've done the computation correctly before doing the subsetting.
You'll learn how to do that in the next section.

The rules for \texttt{NA} are a bit trickier, so I'll explain them next.

\hypertarget{missing-values}{%
\subsection{Missing values}\label{missing-values}}

\texttt{NA}, R's missing value indicator, can be frustrating to work
with. R's underlying philosophy is to force you to recognise that you
have missing values, and make a deliberate choice to deal with them:
missing values never silently go missing. This is a pain because you
almost always want to just get rid of them, but it's a good principle to
force you to think about the correct option. \indexc{NA}
\index{Missing values}

The most important thing to understand about missing values is that they
are infectious: with few exceptions, the result of any operation that
includes a missing value will be a missing value. This happens because
\texttt{NA} represents an unknown value, and there are few operations
that turn an unknown value into a known value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{x }\OperatorTok{==}\StringTok{ }\DecValTok{1}
\CommentTok{#> [1]  TRUE    NA FALSE}
\NormalTok{x }\OperatorTok{>}\StringTok{ }\DecValTok{2}
\CommentTok{#> [1] FALSE    NA FALSE}
\NormalTok{x }\OperatorTok{+}\StringTok{ }\DecValTok{10}
\CommentTok{#> [1] 11 NA 12}
\end{Highlighting}
\end{Shaded}

When you first learn R, you might be tempted to find missing values
using \texttt{==}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{==}\StringTok{ }\OtherTok{NA}
\CommentTok{#> [1] NA NA NA}
\NormalTok{x }\OperatorTok{!=}\StringTok{ }\OtherTok{NA}
\CommentTok{#> [1] NA NA NA}
\end{Highlighting}
\end{Shaded}

But that doesn't work! A little thought reveals why: there's no reason
why two unknown values should be the same. Instead, use
\texttt{is.na(X)} to determine if a value is missing: \indexf{is.na}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{is.na}\NormalTok{(x)}
\CommentTok{#> [1] FALSE  TRUE FALSE}
\end{Highlighting}
\end{Shaded}

\texttt{filter()} only includes observations where all arguments are
\texttt{TRUE}, so \texttt{NA} values are automatically dropped. If you
want to include missing values, be explicit:
\texttt{x\ \textgreater{}\ 10\ \textbar{}\ is.na(x)}. In other parts of
R, you'll sometimes need to convert missing values into \texttt{FALSE}.
You can do that with \texttt{x\ \textgreater{}\ 10\ \&\ !is.na(x)}

\hypertarget{exercises}{%
\subsection{Exercises}\label{exercises}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Practice your filtering skills by:

  \begin{itemize}
  \tightlist
  \item
    Finding all the diamonds with equal x and y dimensions.
  \item
    A depth between 55 and 70.
  \item
    A carat smaller than the median carat.
  \item
    Cost more than \$10,000 per carat
  \item
    Are of good or better quality
  \end{itemize}
\item
  Fill in the question marks in this table:

  \begin{longtable}[]{@{}llll@{}}
  \toprule
  Expression & \texttt{TRUE} & \texttt{FALSE} &
  \texttt{NA}\tabularnewline
  \midrule
  \endhead
  \texttt{x} & x & &\tabularnewline
  ? & & x &\tabularnewline
  \texttt{is.na(x)} & & & x\tabularnewline
  \texttt{!is.na(x)} & ? & ? & ?\tabularnewline
  ? & x & & x\tabularnewline
  ? & & x & x\tabularnewline
  \bottomrule
  \end{longtable}
\item
  Repeat the analysis of outlying values with \texttt{z}. Compared to
  \texttt{x} and \texttt{y}, how would you characterise the relationship
  of \texttt{x} and \texttt{z}, or \texttt{y} and \texttt{z}?
\item
  Install the \textbf{ggplot2movies} package and look at the movies that
  have a missing budget. How are they different from the movies with a
  budget? (Hint: try a frequency polygon plus
  \texttt{colour\ =\ is.na(budget)}.)
\item
  What is \texttt{NA\ \&\ FALSE} and \texttt{NA\ \textbar{}\ TRUE}? Why?
  Why doesn't \texttt{NA\ *\ 0} equal zero? What number times zero does
  not equal 0? What do you expect \texttt{NA\ \^{}\ 0} to equal? Why?
\end{enumerate}

\hypertarget{mutate}{%
\section{Create new variables}\label{mutate}}

To better explore the relationship between \texttt{x} and \texttt{y},
it's useful to ``rotate'' the plot so that the data is flat, not
diagonal. We can do that by creating two new variables: one that
represents the difference between \texttt{x} and \texttt{y} (which in
this context represents the symmetry of the diamond) and one that
represents its size (the length of the diagonal). \indexf{mutate}
\index{Data!creating new variables}

To create new variables use \texttt{mutate()}. Like \texttt{filter()} it
takes a data frame as its first argument and returns a data frame. Its
second and subsequent arguments are named expressions that generate new
variables. Like \texttt{filter()} you can refer to variables just by
their name, you don't need to also include the name of the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds_ok2 <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(diamonds_ok,}
  \DataTypeTok{sym =}\NormalTok{ x }\OperatorTok{-}\StringTok{ }\NormalTok{y,}
  \DataTypeTok{size =} \KeywordTok{sqrt}\NormalTok{(x }\OperatorTok{^}\StringTok{ }\DecValTok{2} \OperatorTok{+}\StringTok{ }\NormalTok{y }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)}
\NormalTok{)}
\NormalTok{diamonds_ok2}
\CommentTok{#> # A tibble: 53,930 x 12}
\CommentTok{#>   carat cut       color clari~ depth table price     x     y     z}
\CommentTok{#>   <dbl> <ord>     <ord> <ord>  <dbl> <dbl> <int> <dbl> <dbl> <dbl>}
\CommentTok{#> 1 0.230 Ideal     E     SI2     61.5  55.0   326  3.95  3.98  2.43}
\CommentTok{#> 2 0.210 Premium   E     SI1     59.8  61.0   326  3.89  3.84  2.31}
\CommentTok{#> 3 0.230 Good      E     VS1     56.9  65.0   327  4.05  4.07  2.31}
\CommentTok{#> 4 0.290 Premium   I     VS2     62.4  58.0   334  4.20  4.23  2.63}
\CommentTok{#> 5 0.310 Good      J     SI2     63.3  58.0   335  4.34  4.35  2.75}
\CommentTok{#> 6 0.240 Very Good J     VVS2    62.8  57.0   336  3.94  3.96  2.48}
\CommentTok{#> # ... with 5.392e+04 more rows, and 2 more variables: sym <dbl>,}
\CommentTok{#> #   size <dbl>}

\KeywordTok{ggplot}\NormalTok{(diamonds_ok2, }\KeywordTok{aes}\NormalTok{(size, sym)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_bin2d}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/mutate1-1}
\end{figure}

This plot has two advantages: we can more easily see the pattern
followed by most diamonds, and we can easily select outliers. Here, it
doesn't seem important whether the outliers are positive (i.e.
\texttt{x} is bigger than \texttt{y}) or negative (i.e. \texttt{y} is
bigger \texttt{x}). So we can use the absolute value of the symmetry
variable to pull out the outliers. Based on the plot, and a little
experimentation, I came up with a threshold of 0.20. We'll check out the
results with a histogram.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(diamonds_ok2, }\KeywordTok{aes}\NormalTok{(}\KeywordTok{abs}\NormalTok{(sym))) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{0.10}\NormalTok{)}

\NormalTok{diamonds_ok3 <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(diamonds_ok2, }\KeywordTok{abs}\NormalTok{(sym) }\OperatorTok{<}\StringTok{ }\FloatTok{0.20}\NormalTok{)}
\KeywordTok{ggplot}\NormalTok{(diamonds_ok3, }\KeywordTok{aes}\NormalTok{(}\KeywordTok{abs}\NormalTok{(sym))) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \includegraphics[width=0.5\linewidth]{_figures/data-manip/sym-hist-1}%
  \includegraphics[width=0.5\linewidth]{_figures/data-manip/sym-hist-2}
\end{figure}

That's an interesting histogram! While most diamonds are close to being
symmetric there are very few that are perfectly symmetric (i.e.
\texttt{x\ ==\ y}).

\hypertarget{useful-tools-1}{%
\subsection{Useful tools}\label{useful-tools-1}}

Typically, transformations will be suggested by your domain knowledge.
However, there are a few transformations that are useful in a
surprisingly wide range of circumstances.

\begin{itemize}
\item
  Log-transformations are often useful. They turn multiplicative
  relationships into additive relationships; they compress data that
  varies over orders of magnitude; they convert power relationships to
  linear relationship. See examples at
  \url{http://stats.stackexchange.com/questions/27951}
\item
  Relative difference: If you're interested in the relative difference
  between two variables, use \texttt{log(x\ /\ y)}. It's better than
  \texttt{x\ /\ y} because it's symmetric: if x \textless{} y,
  \texttt{x\ /\ y} takes values {[}0, 1), but if x \textgreater{} y,
  \texttt{x\ /\ y} takes values (1, Inf). See Törnqvist, Vartia, and
  Vartia (1985) for more details. \indexf{log}
\item
  Sometimes integrating or differentiating might make the data more
  interpretable: if you have distance and time, would speed or
  acceleration be more useful? (or vice versa). (Note that integration
  makes data more smooth; differentiation makes it less smooth.)
\item
  Partition a number into magnitude and direction with \texttt{abs(x)}
  and \texttt{sign(x)}.
\end{itemize}

There are also a few useful ways to transform pairs of variables:

\begin{itemize}
\item
  Partitioning into overall size and difference is often useful, as seen
  above.
\item
  If you see a strong trend, use a model to partition it into pattern
  and residuals is often useful. You'll learn more about that in the
  next chapter.
\item
  Sometimes it's useful to change positions to polar coordinates (or
  vice versa): distance (\texttt{sqrt(x\^{}2\ +\ y\^{}2)}) and angle
  (\texttt{atan2(y,\ x)}).
\end{itemize}

\hypertarget{exercises-1}{%
\subsection{Exercises}\label{exercises-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Practice your variable creation skills by creating the following new
  variables:

  \begin{itemize}
  \tightlist
  \item
    The approximate volume of the diamond (using x, y, and z).
  \item
    The approximate density of the diamond.
  \item
    The price per carat.
  \item
    Log transformation of carat and price.
  \end{itemize}
\item
  How can you improve the data density of
  \texttt{ggplot(diamonds,\ aes(x,\ z))\ +\ stat\_bin2d()}. What
  transformation makes it easier to extract outliers?
\item
  The depth variable is just the width of the diamond (average of
  \texttt{x} and \texttt{y}) divided by its height (\texttt{z})
  multiplied by 100 and round to the nearest integer. Compute the depth
  yourself and compare it to the existing depth variable. Summarise your
  findings with a plot.
\item
  Compare the distribution of symmetry for diamonds with \(x > y\) vs.
  \(x < y\).
\end{enumerate}

\hypertarget{sec:summarise}{%
\section{Group-wise summaries}\label{sec:summarise}}

Many insightful visualisations require that you reduce the full dataset
down to a meaningful summary. ggplot2 provides a number of geoms that
will do summaries for you. But it's often useful to do summaries by
hand: that gives you more flexibility and you can use the summaries for
other purposes. \indexf{group\_by} \indexf{summarise}

dplyr does summaries in two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define the grouping variables with \texttt{group\_by()}.
\item
  Describe how to summarise each group with a single row with
  \texttt{summarise()}
\end{enumerate}

For example, to look at the average price per clarity, we first group by
clarity, then summarise:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by_clarity <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(diamonds, clarity)}
\NormalTok{sum_clarity <-}\StringTok{ }\KeywordTok{summarise}\NormalTok{(by_clarity, }\DataTypeTok{price =} \KeywordTok{mean}\NormalTok{(price))}
\NormalTok{sum_clarity}
\CommentTok{#> # A tibble: 8 x 2}
\CommentTok{#>   clarity price}
\CommentTok{#>   <ord>   <dbl>}
\CommentTok{#> 1 I1       3924}
\CommentTok{#> 2 SI2      5063}
\CommentTok{#> 3 SI1      3996}
\CommentTok{#> 4 VS2      3925}
\CommentTok{#> 5 VS1      3839}
\CommentTok{#> 6 VVS2     3284}
\CommentTok{#> # ... with 2 more rows}

\KeywordTok{ggplot}\NormalTok{(sum_clarity, }\KeywordTok{aes}\NormalTok{(clarity, price)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group =} \DecValTok{1}\NormalTok{), }\DataTypeTok{colour =} \StringTok{"grey80"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/price-by-clarity-1}
\end{figure}

You might be surprised by this pattern: why do diamonds with better
clarity have lower prices? We'll see why this is the case and what to do
about it in \protect\hyperlink{sub:trend}{removing trend}.

Supply additional variables to \texttt{group\_by()} to create groups
based on more than one variable. The next example shows how we can
compute (by hand) a frequency polygon that shows how cut and depth
interact. The special summary function \texttt{n()} counts the number of
observations in each group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\KeywordTok{group_by}\NormalTok{(diamonds, cut, depth), }\DataTypeTok{n =} \KeywordTok{n}\NormalTok{())}
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(cut_depth, depth }\OperatorTok{>}\StringTok{ }\DecValTok{55}\NormalTok{, depth }\OperatorTok{<}\StringTok{ }\DecValTok{70}\NormalTok{)}
\NormalTok{cut_depth}
\CommentTok{#> # A tibble: 455 x 3}
\CommentTok{#> # Groups: cut [5]}
\CommentTok{#>   cut   depth     n}
\CommentTok{#>   <ord> <dbl> <int>}
\CommentTok{#> 1 Fair   55.1     3}
\CommentTok{#> 2 Fair   55.2     6}
\CommentTok{#> 3 Fair   55.3     5}
\CommentTok{#> 4 Fair   55.4     2}
\CommentTok{#> 5 Fair   55.5     3}
\CommentTok{#> 6 Fair   55.6     4}
\CommentTok{#> # ... with 449 more rows}

\KeywordTok{ggplot}\NormalTok{(cut_depth, }\KeywordTok{aes}\NormalTok{(depth, n, }\DataTypeTok{colour =}\NormalTok{ cut)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/freqpoly-by-hand-1}
\end{figure}

We can use a grouped \texttt{mutate()} to convert counts to proportions,
so it's easier to compare across the cuts. \texttt{summarise()} strips
one level of grouping off, so \texttt{cut\_depth} will be grouped by
cut.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cut_depth, }\DataTypeTok{prop =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n))}
\KeywordTok{ggplot}\NormalTok{(cut_depth, }\KeywordTok{aes}\NormalTok{(depth, prop, }\DataTypeTok{colour =}\NormalTok{ cut)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/freqpoly-scaled-1}
\end{figure}

\hypertarget{useful-tools-2}{%
\subsection{Useful tools}\label{useful-tools-2}}

\texttt{summarise()} needs to be used with functions that take a vector
of \(n\) values and always return a single value. Those functions
include:

\begin{itemize}
\tightlist
\item
  Counts: \texttt{n()}, \texttt{n\_distinct(x)}.
\item
  Middle: \texttt{mean(x)}, \texttt{median(x)}.
\item
  Spread: \texttt{sd(x)}, \texttt{mad(x)}, \texttt{IQR(x)}.
\item
  Extremes: \texttt{quartile(x)}, \texttt{min(x)}, \texttt{max(x)}.
\item
  Positions: \texttt{first(x)}, \texttt{last(x)}, \texttt{nth(x,\ 2)}.
\end{itemize}

Another extremely useful technique is to use \texttt{sum()} or
\texttt{mean()} with a logical vector. When a logical vector is treated
as numeric, \texttt{TRUE} becomes 1 and \texttt{FALSE} becomes 0. This
means that \texttt{sum()} tells you the number of \texttt{TRUE}s, and
\texttt{mean()} tells you the proportion of \texttt{TRUE}s. For example,
the following code counts the number of diamonds with carat greater than
or equal to 4, and the proportion of diamonds that cost less than
\$1000.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summarise}\NormalTok{(diamonds, }
  \DataTypeTok{n_big =} \KeywordTok{sum}\NormalTok{(carat }\OperatorTok{>=}\StringTok{ }\DecValTok{4}\NormalTok{), }
  \DataTypeTok{prop_cheap =} \KeywordTok{mean}\NormalTok{(price }\OperatorTok{<}\StringTok{ }\DecValTok{1000}\NormalTok{)}
\NormalTok{)}
\CommentTok{#> # A tibble: 1 x 2}
\CommentTok{#>   n_big prop_cheap}
\CommentTok{#>   <int>      <dbl>}
\CommentTok{#> 1     6      0.269}
\end{Highlighting}
\end{Shaded}

Most summary functions have a \texttt{na.rm} argument:
\texttt{na.rm\ =\ TRUE} tells the summary function to remove any missing
values prior to summiarisation. This is a convenient shortcut: rather
than removing the missing values then summarising, you can do it in one
step.

\hypertarget{statistical-considerations}{%
\subsection{Statistical
considerations}\label{statistical-considerations}}

When summarising with the mean or median, it's always a good idea to
include a count and a measure of spread. This helps you calibrate your
assessments - if you don't include them you're likely to think that the
data is less variable than it really is, and potentially draw
unwarranted conclusions.

The following example extends our previous summary of the average price
by clarity to also include the number of observations in each group, and
the upper and lower quartiles. It suggests the mean might be a bad
summary for this data - the distributions of price are so highly skewed
that the mean is higher than the upper quartile for some of the groups!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{by_clarity <-}\StringTok{ }\NormalTok{diamonds }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(clarity) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}
    \DataTypeTok{n =} \KeywordTok{n}\NormalTok{(), }
    \DataTypeTok{mean =} \KeywordTok{mean}\NormalTok{(price), }
    \DataTypeTok{lq =} \KeywordTok{quantile}\NormalTok{(price, }\FloatTok{0.25}\NormalTok{), }
    \DataTypeTok{uq =} \KeywordTok{quantile}\NormalTok{(price, }\FloatTok{0.75}\NormalTok{)}
\NormalTok{  )}
\NormalTok{by_clarity}
\CommentTok{#> # A tibble: 8 x 5}
\CommentTok{#>   clarity     n  mean    lq    uq}
\CommentTok{#>   <ord>   <int> <dbl> <dbl> <dbl>}
\CommentTok{#> 1 I1        741  3924  2080  5161}
\CommentTok{#> 2 SI2      9194  5063  2264  5777}
\CommentTok{#> 3 SI1     13065  3996  1089  5250}
\CommentTok{#> 4 VS2     12258  3925   900  6024}
\CommentTok{#> 5 VS1      8171  3839   876  6023}
\CommentTok{#> 6 VVS2     5066  3284   794  3638}
\CommentTok{#> # ... with 2 more rows}
\KeywordTok{ggplot}\NormalTok{(by_clarity, }\KeywordTok{aes}\NormalTok{(clarity, mean)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_linerange}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{ymin =}\NormalTok{ lq, }\DataTypeTok{ymax =}\NormalTok{ uq)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group =} \DecValTok{1}\NormalTok{), }\DataTypeTok{colour =} \StringTok{"grey50"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{size =}\NormalTok{ n))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/unnamed-chunk-2-1}
\end{figure}

Another example of this comes from baseball. Let's take the MLB batting
data from the Lahman package and calculate the batting average: the
number of hits divided by the number of at bats. Who's the best batter
according to this metric?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(Batting, }\DataTypeTok{package =} \StringTok{"Lahman"}\NormalTok{)}
\NormalTok{batters <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(Batting, AB }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{)}
\NormalTok{per_player <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(batters, playerID)}
\NormalTok{ba <-}\StringTok{ }\KeywordTok{summarise}\NormalTok{(per_player, }
  \DataTypeTok{ba =} \KeywordTok{sum}\NormalTok{(H, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(AB, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{)}
\KeywordTok{ggplot}\NormalTok{(ba, }\KeywordTok{aes}\NormalTok{(ba)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/unnamed-chunk-3-1}
\end{figure}

Wow, there are a lot of players who can hit the ball every single time!
Would you want them on your fantasy baseball team? Let's double check
they're really that good by calibrating also showing the total number of
at bats:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ba <-}\StringTok{ }\KeywordTok{summarise}\NormalTok{(per_player, }
  \DataTypeTok{ba =} \KeywordTok{sum}\NormalTok{(H, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(AB, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{),}
  \DataTypeTok{ab =} \KeywordTok{sum}\NormalTok{(AB, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{)}
\KeywordTok{ggplot}\NormalTok{(ba, }\KeywordTok{aes}\NormalTok{(ab, ba)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bin2d}\NormalTok{(}\DataTypeTok{bins =} \DecValTok{100}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{()}
\CommentTok{#> `geom_smooth()` using method = 'gam'}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/unnamed-chunk-4-1}
\end{figure}

The highest batting averages occur for the players with the smallest
number of at bats - it's not hard to hit the ball every time if you've
only had two pitches. We can make the pattern a little more clear by
getting rid of the players with less than 10 at bats.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{filter}\NormalTok{(ba, ab }\OperatorTok{>=}\StringTok{ }\DecValTok{10}\NormalTok{), }\KeywordTok{aes}\NormalTok{(ab, ba)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bin2d}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{()}
\CommentTok{#> `geom_smooth()` using method = 'gam'}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\linewidth]{_figures/data-manip/unnamed-chunk-5-1}
\end{figure}

You'll often see a similar pattern whenever you plot number of
observations vs.~an average. Be aware!

\hypertarget{exercises-2}{%
\subsection{Exercises}\label{exercises-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  For each year in the \texttt{ggplot2movies::movies} data determine the
  percent of movies with missing budgets. Visualise the result.
\item
  How does the average length of a movie change over time? Display your
  answer with a plot, including some display of uncertainty.
\item
  For each combination of diamond quality (e.g.~cut, colour and
  clarity), count the number of diamonds, the average price and the
  average size. Visualise the results.
\item
  Compute a histogram of carat by ``hand'' using a binwidth of 0.1.
  Display the results with \texttt{geom\_bar(stat\ =\ "identity")}.
  (Hint: you might need to create a new variable first).
\item
  In the baseball example, the batting average seems to increase as the
  number of at bats increases. Why?
\end{enumerate}

\hypertarget{transformation-pipelines}{%
\section{Transformation pipelines}\label{transformation-pipelines}}

Most real analyses require you to string together multiple
\texttt{mutate()}s, \texttt{filter()}s, \texttt{group\_by()}s , and
\texttt{summarise()}s. For example, above, we created a frequency
polygon by hand with a combination of all four verbs: \indexc{\%>\%}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# By using intermediate values}
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{group_by}\NormalTok{(diamonds, cut, depth)}
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{summarise}\NormalTok{(cut_depth, }\DataTypeTok{n =} \KeywordTok{n}\NormalTok{())}
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{filter}\NormalTok{(cut_depth, depth }\OperatorTok{>}\StringTok{ }\DecValTok{55}\NormalTok{, depth }\OperatorTok{<}\StringTok{ }\DecValTok{70}\NormalTok{)}
\NormalTok{cut_depth <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(cut_depth, }\DataTypeTok{prop =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

This sequence of operations is a bit painful because we repeated the
name of the data frame many times. An alternative is just to do it with
one sequence of function calls:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# By "composing" functions}
\KeywordTok{mutate}\NormalTok{(}
  \KeywordTok{filter}\NormalTok{(}
    \KeywordTok{summarise}\NormalTok{(}
      \KeywordTok{group_by}\NormalTok{(}
\NormalTok{        diamonds, }
\NormalTok{        cut, }
\NormalTok{        depth}
\NormalTok{      ), }
      \DataTypeTok{n =} \KeywordTok{n}\NormalTok{()}
\NormalTok{    ), }
\NormalTok{    depth }\OperatorTok{>}\StringTok{ }\DecValTok{55}\NormalTok{, }
\NormalTok{    depth }\OperatorTok{<}\StringTok{ }\DecValTok{70}
\NormalTok{  ), }
  \DataTypeTok{prop =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

But this is also hard to read because the sequence of operations is
inside out, and the arguments to each function can be quite far apart.
dplyr provides an alternative approach with the \textbf{pipe},
\texttt{\%\textgreater{}\%}. With the pipe, we can write the above
sequence of operations as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cut_depth <-}\StringTok{ }\NormalTok{diamonds }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cut, depth) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(depth }\OperatorTok{>}\StringTok{ }\DecValTok{55}\NormalTok{, depth }\OperatorTok{<}\StringTok{ }\DecValTok{70}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prop =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

This makes it easier to understand what's going on as we can read it
almost like an English sentence: first group, then summarise, then
filter, then mutate. In fact, the best way to pronounce
\texttt{\%\textgreater{}\%} when reading a sequence of code is as
``then''. \texttt{\%\textgreater{}\%} comes from the magrittr package,
by Stefan Milton Bache. It provides a number of other tools that dplyr
doesn't expose by default, so I highly recommend that you check out the
\href{https://github.com/smbache/magrittr}{magrittr website}.
\index{magrittr}

\texttt{\%\textgreater{}\%} works by taking the thing on the left hand
side (LHS) and supplying it as the first argument to the function on the
right hand side (RHS). Each of these pairs of calls is equivalent:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{f}\NormalTok{(x, y)}
\CommentTok{# is the same as}
\NormalTok{x }\OperatorTok{%>%}\StringTok{ }\KeywordTok{f}\NormalTok{(y)}

\KeywordTok{g}\NormalTok{(}\KeywordTok{f}\NormalTok{(x, y), z)}
\CommentTok{# is the same as}
\NormalTok{x }\OperatorTok{%>%}\StringTok{ }\KeywordTok{f}\NormalTok{(y) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{g}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercises-3}{%
\subsection{Exercises}\label{exercises-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Translate each of the examples in this chapter to use the pipe.
\item
  What does the following pipe do?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}
\NormalTok{x <-}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{x }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{subtract}\NormalTok{(}\KeywordTok{mean}\NormalTok{(.)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{raise_to_power}\NormalTok{(}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mean}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{sqrt}\NormalTok{()}
\end{Highlighting}
\end{Shaded}
\item
  Which player in the \texttt{Batting} dataset has had the most
  consistently good performance over the course of their career?
\end{enumerate}

\hypertarget{learning-more}{%
\section{Learning more}\label{learning-more}}

dplyr provides a number of other verbs that are less useful for
visualisation, but important to know about in general:

\begin{itemize}
\item
  \texttt{arrange()} orders observations according to variable(s). This
  is most useful when you're looking at the data from the console. It
  can also be useful for visualisations if you want to control which
  points are plotted on top.
\item
  \texttt{select()} picks variables based on their names. Useful when
  you have many variables and want to focus on just a few for analysis.
\item
  \texttt{rename()} allows you to change the name of variables.
\item
  Grouped mutates and filters are also useful, but more advanced. See
  \texttt{vignette("window-functions",\ package\ =\ "dplyr")} for more
  details.
\item
  There are a number of verbs designed to work with two tables of data
  at a time. These include SQL joins (like the base \texttt{merge()}
  function) and set operations. Learn more about them in
  \texttt{vignette("two-table",\ package\ =\ "dplyr")}.
\item
  dplyr can work directly with data stored in a database - you use the
  same R code as you do for local data and dplyr generates SQL to send
  to the database. See
  \texttt{vignette("databases",\ package\ =\ "dplyr")} for the details.
\end{itemize}

Finally, RStudio provides a handy dplyr cheatsheet that will help jog
your memory when you're wondering which function to use. Get it from
\url{http://rstudio.com/cheatsheets}.

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-tornqvist:1985}{}%
Törnqvist, Leo, Pentti Vartia, and Yrjö O Vartia. 1985. ``How Should
Relative Changes Be Measured?'' \emph{The American Statistician} 39
(1):43--46.
