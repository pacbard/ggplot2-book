\hypertarget{cha:data}{%
\chapter{Data analysis}\label{cha:data}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

So far, every example in this book has started with a nice dataset
that's easy to plot. That's great for learning (because you don't want
to struggle with data handling while you're learning visualisation), but
in real life, datasets hardly ever come in exactly the right structure.
To use ggplot2 in practice, you'll need to learn some data wrangling
skills. Indeed, in my experience, visualisation is often the easiest
part of the data analysis process: once you have the right data, in the
right format, aggregated in the right way, the right visualisation is
often obvious.

The goal of this part of the book is to show you how to integrate
ggplot2 with other tools needed for a complete data analysis:

\begin{itemize}
\item
  In this chapter, you'll learn the principles of tidy data (Wickham
  2014), which help you organise your data in a way that makes it easy
  to visualise with ggplot2, manipulate with dplyr and model with the
  many modelling packages. The principles of tidy data are supported by
  the \textbf{tidyr} package, which helps you tidy messy datasets.
\item
  Most visualisations require some data transformation whether it's
  creating a new variable from existing variables, or performing simple
  aggregations so you can see the forest for the trees.
  \protect\hyperlink{cha:dplyr}{dplyr} will show you how to do this with
  the \textbf{dplyr} package.
\item
  If you're using R, you're almost certainly using it for its fantastic
  modelling capabilities. While there's an R package for almost every
  type of model that you can think of, the results of these models can
  be hard to visualise. In \protect\hyperlink{cha:modelling}{modelling},
  you'll learn about the \textbf{broom} package, by David Robinson, to
  convert models into tidy datasets so you can easily visualise them
  with ggplot2.
\end{itemize}

Tidy data is the foundation for data manipulation and visualising
models. In the following sections, you'll learn the definition of tidy
data, and the tools you need to make messy data tidy. The chapter
concludes with two case studies that show how to apply the tools in
sequence to work with real(istic) data.

\hypertarget{sec:tidy-data}{%
\section{Tidy data}\label{sec:tidy-data}}

The principle behind tidy data is simple: storing your data in a
consistent way makes it easier to work with it. Tidy data is a mapping
between the statistical structure of a data frame (variables and
observations) and the physical structure (columns and rows). Tidy data
follows two main principles: \index{Tidy data}
\index{Data!best form for ggplot2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Variables go in columns.
\item
  Observations go in rows.
\end{enumerate}

Tidy data is particularly important for ggplot2 because the job of
ggplot2 is to map variables to visual properties: if your data isn't
tidy, you'll have a hard time visualising it.

Sometimes you'll find a dataset that you have no idea how to plot.
That's normally because it's not tidy. For example, take this data frame
that contains monthly employment data for the United States:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ec2}
\CommentTok{#> # A tibble: 12 x 11}
\CommentTok{#>   month `2006` `2007` `2008` `2009` `2010` `201~ `201~ `201~ `201~}
\CommentTok{#> * <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>}
\CommentTok{#> 1  1.00   8.60   8.30   9.00   10.7   20.0  21.6  21.0  16.2  15.9}
\CommentTok{#> 2  2.00   9.10   8.50   8.70   11.7   19.9  21.1  19.8  17.5  16.2}
\CommentTok{#> 3  3.00   8.70   9.10   8.70   12.3   20.4  21.5  19.2  17.7  15.9}
\CommentTok{#> 4  4.00   8.40   8.60   9.40   13.1   22.1  20.9  19.1  17.1  15.6}
\CommentTok{#> 5  5.00   8.50   8.20   7.90   14.2   22.3  21.6  19.9  17.0  14.5}
\CommentTok{#> 6  6.00   7.30   7.70   9.00   17.2   25.2  22.3  20.1  16.6  13.2}
\CommentTok{#> # ... with 6 more rows, and 1 more variable: `2015` <dbl>}
\end{Highlighting}
\end{Shaded}

(If it looks familiar, it's because it's derived from the
\texttt{economics} dataset that we used earlier in the book.)

Imagine you want to plot a time series showing how unemployment has
changed over the last 10 years. Can you picture the ggplot2 command
you'd need to do it? What if you wanted to focus on the seasonal
component of unemployment by putting months on the x-axis and drawing
one line for each year? It's difficult to see how to create those plots
because the data is not tidy. There are three variables, month, year and
unemployment rate, but each variable is stored in a different way:

\begin{itemize}
\tightlist
\item
  \texttt{month} is stored in a column.
\item
  \texttt{year} is spread across the column names.
\item
  \texttt{rate} is the value of each cell.
\end{itemize}

To make it possible to plot this data we first need to tidy it. There
are two important pairs of tools:

\begin{itemize}
\tightlist
\item
  Spread \& gather.
\item
  Separate \& unite.
\end{itemize}

\hypertarget{sec:spread-gather}{%
\section{Spread and gather}\label{sec:spread-gather}}

Take a look at the two tables below:

\begin{longtable}[]{@{}llr@{}}
\toprule
x & y & z\tabularnewline
\midrule
\endhead
a & A & 1\tabularnewline
b & D & 5\tabularnewline
c & A & 4\tabularnewline
c & B & 10\tabularnewline
d & C & 9\tabularnewline
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}lrrrr@{}}
\toprule
x & A & B & C & D\tabularnewline
\midrule
\endhead
a & 1 & NA & NA & NA\tabularnewline
b & NA & NA & NA & 5\tabularnewline
c & 4 & 10 & NA & NA\tabularnewline
d & NA & NA & 9 & NA\tabularnewline
\bottomrule
\end{longtable}

If you study them for a little while, you'll notice that they contain
the same data in different forms. I call the first form \textbf{indexed}
data, because you look up a value using an index (the values of the
\texttt{x} and \texttt{y} variables). I call the second form
\textbf{Cartesian} data, because you find a value by looking at
intersection of a row and a column. We can't tell if these datasets are
tidy or not. Either form could be tidy depending on what the values
``A'', ``B'', ``C'', ``D'' mean.

(Also note the missing values: missing values that are explicit in one
form may be implicit in the other. An \texttt{NA} is the presence of an
absense; but sometimes a missing value is the absense of a presence.)

Tidying your data will often require translating Cartesian → indexed
forms, called \textbf{gathering}, and less commonly, indexed →
Cartesian, called \textbf{spreading}. The tidyr package provides the
\texttt{spread()} and \texttt{gather()} functions to perform these
operations, as described below.

(You can imagine generalising these ideas to higher dimensions. However,
data is almost always stored in 2d (rows \& columns), so these
generalisations are fun to think about, but not that practical. I
explore the idea more in Wickham (2007).

\hypertarget{gather}{%
\subsection{Gather}\label{gather}}

\texttt{gather()} has four main arguments: \indexf{gather}

\begin{itemize}
\item
  \texttt{data}: the dataset to translate.
\item
  \texttt{key} \& \texttt{value}: the key is the name of the variable
  that will be created from the column names, and the value is the name
  of the variable that will be created from the cell values.
\item
  \texttt{...}: which variables to gather. You can specify individually,
  \texttt{A,\ B,\ C,\ D}, or as a range \texttt{A:D}. Alternatively, you
  can specify which columns are \emph{not} to be gathered with
  \texttt{-}: \texttt{-E,\ -F}.
\end{itemize}

To tidy the economics dataset shown above, you first need to identify
the variables: \texttt{year}, \texttt{month} and \texttt{rate}.
\texttt{month} is already in a column, but \texttt{year} and
\texttt{rate} are in Cartesian form, and we want them in indexed form,
so we need to use \texttt{gather()}. In this example, the key is
\texttt{year}, the value is \texttt{unemp} and we want to select columns
from \texttt{2006} to \texttt{2015}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gather}\NormalTok{(ec2, }\DataTypeTok{key =}\NormalTok{ year, }\DataTypeTok{value =}\NormalTok{ unemp, }\StringTok{`}\DataTypeTok{2006}\StringTok{`}\OperatorTok{:}\StringTok{`}\DataTypeTok{2015}\StringTok{`}\NormalTok{)}
\CommentTok{#> # A tibble: 120 x 3}
\CommentTok{#>   month year  unemp}
\CommentTok{#>   <dbl> <chr> <dbl>}
\CommentTok{#> 1  1.00 2006   8.60}
\CommentTok{#> 2  2.00 2006   9.10}
\CommentTok{#> 3  3.00 2006   8.70}
\CommentTok{#> 4  4.00 2006   8.40}
\CommentTok{#> 5  5.00 2006   8.50}
\CommentTok{#> 6  6.00 2006   7.30}
\CommentTok{#> # ... with 114 more rows}
\end{Highlighting}
\end{Shaded}

Note that the columns have names that are not standard variable names in
R (they don't start with a letter). This means that we need to surround
them in backticks, i.e. \texttt{\textasciigrave{}2006\textasciigrave{}}
to refer to them.

Alternatively, we could gather all columns except \texttt{month}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gather}\NormalTok{(ec2, }\DataTypeTok{key =}\NormalTok{ year, }\DataTypeTok{value =}\NormalTok{ unemp, }\OperatorTok{-}\NormalTok{month)}
\CommentTok{#> # A tibble: 120 x 3}
\CommentTok{#>   month year  unemp}
\CommentTok{#>   <dbl> <chr> <dbl>}
\CommentTok{#> 1  1.00 2006   8.60}
\CommentTok{#> 2  2.00 2006   9.10}
\CommentTok{#> 3  3.00 2006   8.70}
\CommentTok{#> 4  4.00 2006   8.40}
\CommentTok{#> 5  5.00 2006   8.50}
\CommentTok{#> 6  6.00 2006   7.30}
\CommentTok{#> # ... with 114 more rows}
\end{Highlighting}
\end{Shaded}

To be most useful, we can provide two extra arguments:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{economics_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(ec2, year, rate, }\StringTok{`}\DataTypeTok{2006}\StringTok{`}\OperatorTok{:}\StringTok{`}\DataTypeTok{2015}\StringTok{`}\NormalTok{, }
  \DataTypeTok{convert =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{economics_}\DecValTok{2}
\CommentTok{#> # A tibble: 112 x 3}
\CommentTok{#>   month  year  rate}
\CommentTok{#> * <dbl> <int> <dbl>}
\CommentTok{#> 1  1.00  2006  8.60}
\CommentTok{#> 2  2.00  2006  9.10}
\CommentTok{#> 3  3.00  2006  8.70}
\CommentTok{#> 4  4.00  2006  8.40}
\CommentTok{#> 5  5.00  2006  8.50}
\CommentTok{#> 6  6.00  2006  7.30}
\CommentTok{#> # ... with 106 more rows}
\end{Highlighting}
\end{Shaded}

We use \texttt{convert\ =\ TRUE} to automatically convert the years from
character strings to numbers, and \texttt{na.rm\ =\ TRUE} to remove the
months with no data. (In some sense the data isn't actually missing
because it represents dates that haven't occurred yet.)

When the data is in this form, it's easy to visualise in many different
ways. For example, we can choose to emphasise either long term trend or
seasonal variations:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(economics_}\DecValTok{2}\NormalTok{, }\KeywordTok{aes}\NormalTok{(year }\OperatorTok{+}\StringTok{ }\NormalTok{(month }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{/}\StringTok{ }\DecValTok{12}\NormalTok{, rate)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}

\KeywordTok{ggplot}\NormalTok{(economics_}\DecValTok{2}\NormalTok{, }\KeywordTok{aes}\NormalTok{(month, rate, }\DataTypeTok{group =}\NormalTok{ year)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{colour =}\NormalTok{ year), }\DataTypeTok{size =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \includegraphics[width=0.5\linewidth]{_figures/tidy_data/ec2-plots-1}%
  \includegraphics[width=0.5\linewidth]{_figures/tidy_data/ec2-plots-2}
\end{figure}

\hypertarget{spread}{%
\subsection{Spread}\label{spread}}

\texttt{spread()} is the opposite of \texttt{gather()}. You use it when
you have a pair of columns that are in indexed form, instead of
Cartesian form. For example, the following example dataset contains
three variables (\texttt{day}, \texttt{rain} and \texttt{temp}), but
\texttt{rain} and \texttt{temp} are stored in indexed form.
\indexf{spread}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weather <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{data_frame}\NormalTok{(}
  \DataTypeTok{day =} \KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{),}
  \DataTypeTok{obs =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"temp"}\NormalTok{, }\StringTok{"rain"}\NormalTok{), }\DataTypeTok{each =} \DecValTok{3}\NormalTok{),}
  \DataTypeTok{val =} \KeywordTok{c}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{23}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{20}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{)}
\NormalTok{weather}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>     day obs     val}
\CommentTok{#>   <int> <chr> <dbl>}
\CommentTok{#> 1     1 temp  23.0 }
\CommentTok{#> 2     2 temp  22.0 }
\CommentTok{#> 3     3 temp  20.0 }
\CommentTok{#> 4     1 rain   0   }
\CommentTok{#> 5     2 rain   0   }
\CommentTok{#> 6     3 rain   5.00}
\end{Highlighting}
\end{Shaded}

Spread allows us to turn this messy indexed form into a tidy Cartesian
form. It shares many of the arguments with \texttt{gather()}. You'll
need to supply the \texttt{data} to translate, as well as the name of
the \texttt{key} column which gives the variable names, and the
\texttt{value} column which contains the cell values. Here the key is
\texttt{obs} and the value is \texttt{val}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{spread}\NormalTok{(weather, }\DataTypeTok{key =}\NormalTok{ obs, }\DataTypeTok{value =}\NormalTok{ val)}
\CommentTok{#> # A tibble: 3 x 3}
\CommentTok{#>     day  rain  temp}
\CommentTok{#> * <int> <dbl> <dbl>}
\CommentTok{#> 1     1  0     23.0}
\CommentTok{#> 2     2  0     22.0}
\CommentTok{#> 3     3  5.00  20.0}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercises}{%
\subsection{Exercises}\label{exercises}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  How can you translate each of the initial example datasets into the
  other form?
\item
  How can you convert back and forth between the \texttt{economics} and
  \texttt{economics\_long} datasets built into ggplot2?
\item
  Install the EDAWR package from \url{https://github.com/rstudio/EDAWR}.
  Tidy the \texttt{storms}, \texttt{population} and \texttt{tb}
  datasets.
\end{enumerate}

\hypertarget{sec:separate-unite}{%
\section{Separate and unite}\label{sec:separate-unite}}

Spread and gather help when the variables are in the wrong place in the
dataset. Separate and unite help when multiple variables are crammed
into one column, or spread across multiple columns. \indexf{separate}
\indexf{unite}

For example, the following dataset stores some information about the
response to a medical treatment. There are three variables (time,
treatment and value), but time and treatment are jammed in one variable
together:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trt <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{data_frame}\NormalTok{(}
  \DataTypeTok{var =} \KeywordTok{paste0}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"beg"}\NormalTok{, }\StringTok{"end"}\NormalTok{), }\DataTypeTok{each =} \DecValTok{3}\NormalTok{), }\StringTok{"_"}\NormalTok{, }\KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{))),}
  \DataTypeTok{val =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{11}\NormalTok{)}
\NormalTok{)}
\NormalTok{trt}
\CommentTok{#> # A tibble: 6 x 2}
\CommentTok{#>   var     val}
\CommentTok{#>   <chr> <dbl>}
\CommentTok{#> 1 beg_a  1.00}
\CommentTok{#> 2 beg_b  4.00}
\CommentTok{#> 3 beg_c  2.00}
\CommentTok{#> 4 end_a 10.0 }
\CommentTok{#> 5 end_b  5.00}
\CommentTok{#> 6 end_c 11.0}
\end{Highlighting}
\end{Shaded}

The \texttt{separate()} function makes it easy to tease apart multiple
variables stored in one column. It takes four arguments:

\begin{itemize}
\item
  \texttt{data}: the data frame to modify.
\item
  \texttt{col}: the name of the variable to split into pieces.
\item
  \texttt{into}: a character vector giving the names of the new
  variables.
\item
  \texttt{sep}: a description of how to split the variable apart. This
  can either be a regular expression, e.g. \texttt{\_} to split by
  underscores, or \texttt{{[}\^{}a-z{]}} to split by any non-letter, or
  an integer giving a position.
\end{itemize}

In this case, we want to split by the \texttt{\_} character:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{separate}\NormalTok{(trt, var, }\KeywordTok{c}\NormalTok{(}\StringTok{"time"}\NormalTok{, }\StringTok{"treatment"}\NormalTok{), }\StringTok{"_"}\NormalTok{)}
\CommentTok{#> # A tibble: 6 x 3}
\CommentTok{#>   time  treatment   val}
\CommentTok{#> * <chr> <chr>     <dbl>}
\CommentTok{#> 1 beg   a          1.00}
\CommentTok{#> 2 beg   b          4.00}
\CommentTok{#> 3 beg   c          2.00}
\CommentTok{#> 4 end   a         10.0 }
\CommentTok{#> 5 end   b          5.00}
\CommentTok{#> 6 end   c         11.0}
\end{Highlighting}
\end{Shaded}

(If the variables are combined in a more complex form, have a look at
\texttt{extract()}. Alternatively, you might need to create columns
individually yourself using other calculations. A useful tool for this
is \texttt{mutate()} which you'll learn about in the next chapter.)

\texttt{unite()} is the inverse of \texttt{separate()} - it joins
together multiple columns into one column. This is less common, but it's
useful to know about as the inverse of \texttt{separate()}.

\hypertarget{exercises-1}{%
\subsection{Exercises}\label{exercises-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Install the EDAWR package from \url{https://github.com/rstudio/EDAWR}.
  Tidy the \texttt{who} dataset.
\item
  Work through the demos included in the tidyr package
  (\texttt{demo(package\ =\ "tidyr")})
\end{enumerate}

\hypertarget{sec:tidy-case-study}{%
\section{Case studies}\label{sec:tidy-case-study}}

For most real datasets, you'll need to use more than one tidying verb.
There many be multiple ways to get there, but as long as each step makes
the data tidier, you'll eventually get to the tidy dataset. That said,
you typically apply the functions in the same order: \texttt{gather()},
\texttt{separate()} and \texttt{spread()} (although you might not use
all three).

\hypertarget{blood-pressure}{%
\subsection{Blood pressure}\label{blood-pressure}}

The first step when tidying a new dataset is always to identify the
variables. Take the following simulated medical data. There are seven
variables in this dataset: name, age, start date, week, systolic \&
diastolic blood pressure. Can you see how they're stored?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Adapted from example by Barry Rowlingson, }
\CommentTok{# http://barryrowlingson.github.io/hadleyverse/}
\NormalTok{bpd <-}\StringTok{ }\NormalTok{readr}\OperatorTok{::}\KeywordTok{read_table}\NormalTok{(}
\StringTok{"name age      start  week1  week2  week3}
\StringTok{Anne  35 2014-03-27 100/80 100/75 120/90}
\StringTok{ Ben  41 2014-03-09 110/65 100/65 135/70}
\StringTok{Carl  33 2014-04-02 125/80   <NA>   <NA>}
\StringTok{"}\NormalTok{, }\DataTypeTok{na =} \StringTok{"<NA>"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The first step is to convert from Cartesian to indexed form:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bpd_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(bpd, week, bp, week1}\OperatorTok{:}\NormalTok{week3)}
\NormalTok{bpd_}\DecValTok{1}
\CommentTok{#> # A tibble: 9 x 5}
\CommentTok{#>   name    age start      week  bp    }
\CommentTok{#>   <chr> <int> <date>     <chr> <chr> }
\CommentTok{#> 1 Anne     35 2014-03-27 week1 100/80}
\CommentTok{#> 2 Ben      41 2014-03-09 week1 110/65}
\CommentTok{#> 3 Carl     33 2014-04-02 week1 125/80}
\CommentTok{#> 4 Anne     35 2014-03-27 week2 100/75}
\CommentTok{#> 5 Ben      41 2014-03-09 week2 100/65}
\CommentTok{#> 6 Carl     33 2014-04-02 week2 <NA>  }
\CommentTok{#> # ... with 3 more rows}
\end{Highlighting}
\end{Shaded}

This is tidier, but we have two variables combined together in the
\texttt{bp} variable. This is a common way of writing down the blood
pressure, but analysis is easier if we break it into two variables.
That's the job of separate:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bpd_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{separate}\NormalTok{(bpd_}\DecValTok{1}\NormalTok{, bp, }\KeywordTok{c}\NormalTok{(}\StringTok{"sys"}\NormalTok{, }\StringTok{"dia"}\NormalTok{), }\StringTok{"/"}\NormalTok{)}
\NormalTok{bpd_}\DecValTok{2}
\CommentTok{#> # A tibble: 9 x 6}
\CommentTok{#>   name    age start      week  sys   dia  }
\CommentTok{#> * <chr> <int> <date>     <chr> <chr> <chr>}
\CommentTok{#> 1 Anne     35 2014-03-27 week1 100   80   }
\CommentTok{#> 2 Ben      41 2014-03-09 week1 110   65   }
\CommentTok{#> 3 Carl     33 2014-04-02 week1 125   80   }
\CommentTok{#> 4 Anne     35 2014-03-27 week2 100   75   }
\CommentTok{#> 5 Ben      41 2014-03-09 week2 100   65   }
\CommentTok{#> 6 Carl     33 2014-04-02 week2 <NA>  <NA> }
\CommentTok{#> # ... with 3 more rows}
\end{Highlighting}
\end{Shaded}

This dataset is now tidy, but we could do a little more to make it
easier to use. The following code uses \texttt{extract()} to pull the
week number out into its own variable (using regular expressions is
beyond the scope of the book, but
\texttt{\textbackslash{}\textbackslash{}d} stands for any digit). I also
use \texttt{arrange()} (which you'll learn about in the next chapter) to
order the rows to keep the records for each person together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bpd_}\DecValTok{3}\NormalTok{ <-}\StringTok{ }\KeywordTok{extract}\NormalTok{(bpd_}\DecValTok{2}\NormalTok{, week, }\StringTok{"week"}\NormalTok{, }\StringTok{"(}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{d)"}\NormalTok{, }\DataTypeTok{convert =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{bpd_}\DecValTok{4}\NormalTok{ <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{arrange}\NormalTok{(bpd_}\DecValTok{3}\NormalTok{, name, week)}
\NormalTok{bpd_}\DecValTok{4}
\CommentTok{#> # A tibble: 9 x 6}
\CommentTok{#>   name    age start       week sys   dia  }
\CommentTok{#>   <chr> <int> <date>     <int> <chr> <chr>}
\CommentTok{#> 1 Anne     35 2014-03-27     1 100   80   }
\CommentTok{#> 2 Anne     35 2014-03-27     2 100   75   }
\CommentTok{#> 3 Anne     35 2014-03-27     3 120   90   }
\CommentTok{#> 4 Ben      41 2014-03-09     1 110   65   }
\CommentTok{#> 5 Ben      41 2014-03-09     2 100   65   }
\CommentTok{#> 6 Ben      41 2014-03-09     3 135   70   }
\CommentTok{#> # ... with 3 more rows}
\end{Highlighting}
\end{Shaded}

You might notice that there's some repetition in this dataset: if you
know the name, then you also know the age and start date. This reflects
a third condition of tidyness that I don't discuss here: each data frame
should contain one and only one data set. Here there are really two
datasets: information about each person that doesn't change over time,
and their weekly blood pressure measurements. You can learn more about
this sort of messiness in the resources mentioned at the end of the
chapter.

\hypertarget{test-scores}{%
\subsection{Test scores}\label{test-scores}}

Imagine you're interested in the effect of an intervention on test
scores. You've collected the following data. What are the variables?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Adapted from http://stackoverflow.com/questions/29775461}
\NormalTok{scores <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{data_frame}\NormalTok{(}
  \DataTypeTok{person =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Greg"}\NormalTok{, }\StringTok{"Sally"}\NormalTok{, }\StringTok{"Sue"}\NormalTok{), }\DataTypeTok{each =} \DecValTok{2}\NormalTok{),}
  \DataTypeTok{time   =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"pre"}\NormalTok{, }\StringTok{"post"}\NormalTok{), }\DecValTok{3}\NormalTok{),}
  \DataTypeTok{test1  =} \KeywordTok{round}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{80}\NormalTok{, }\DataTypeTok{sd =} \DecValTok{4}\NormalTok{), }\DecValTok{0}\NormalTok{),}
  \DataTypeTok{test2  =} \KeywordTok{round}\NormalTok{(}\KeywordTok{jitter}\NormalTok{(test1, }\DecValTok{15}\NormalTok{), }\DecValTok{0}\NormalTok{)}
\NormalTok{)}
\NormalTok{scores}
\CommentTok{#> # A tibble: 6 x 4}
\CommentTok{#>   person time  test1 test2}
\CommentTok{#>   <chr>  <chr> <dbl> <dbl>}
\CommentTok{#> 1 Greg   pre    74.0  71.0}
\CommentTok{#> 2 Greg   post   81.0  80.0}
\CommentTok{#> 3 Sally  pre    70.0  69.0}
\CommentTok{#> 4 Sally  post   80.0  78.0}
\CommentTok{#> 5 Sue    pre    82.0  81.0}
\CommentTok{#> 6 Sue    post   85.0  82.0}
\end{Highlighting}
\end{Shaded}

I think the variables are person, test, pre-test score and post-test
score. As usual, we start by converting columns in Cartesian form
(\texttt{test1} and \texttt{test2}) to indexed form (\texttt{test} and
\texttt{score}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scores_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(scores, test, score, test1}\OperatorTok{:}\NormalTok{test2)}
\NormalTok{scores_}\DecValTok{1}
\CommentTok{#> # A tibble: 12 x 4}
\CommentTok{#>   person time  test  score}
\CommentTok{#>   <chr>  <chr> <chr> <dbl>}
\CommentTok{#> 1 Greg   pre   test1  74.0}
\CommentTok{#> 2 Greg   post  test1  81.0}
\CommentTok{#> 3 Sally  pre   test1  70.0}
\CommentTok{#> 4 Sally  post  test1  80.0}
\CommentTok{#> 5 Sue    pre   test1  82.0}
\CommentTok{#> 6 Sue    post  test1  85.0}
\CommentTok{#> # ... with 6 more rows}
\end{Highlighting}
\end{Shaded}

Now we need to do the opposite: \texttt{pre} and \texttt{post} should be
variables, not values, so we need to spread \texttt{time} and
\texttt{score}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scores_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{spread}\NormalTok{(scores_}\DecValTok{1}\NormalTok{, time, score)}
\NormalTok{scores_}\DecValTok{2}
\CommentTok{#> # A tibble: 6 x 4}
\CommentTok{#>   person test   post   pre}
\CommentTok{#> * <chr>  <chr> <dbl> <dbl>}
\CommentTok{#> 1 Greg   test1  81.0  74.0}
\CommentTok{#> 2 Greg   test2  80.0  71.0}
\CommentTok{#> 3 Sally  test1  80.0  70.0}
\CommentTok{#> 4 Sally  test2  78.0  69.0}
\CommentTok{#> 5 Sue    test1  85.0  82.0}
\CommentTok{#> 6 Sue    test2  82.0  81.0}
\end{Highlighting}
\end{Shaded}

A good indication that we have made a tidy dataset is that it's now easy
to calculate the statistic of interest: the difference between pre- and
post-intervention scores:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scores_}\DecValTok{3}\NormalTok{ <-}\StringTok{ }\KeywordTok{mutate}\NormalTok{(scores_}\DecValTok{2}\NormalTok{, }\DataTypeTok{diff =}\NormalTok{ post }\OperatorTok{-}\StringTok{ }\NormalTok{pre)}
\NormalTok{scores_}\DecValTok{3}
\CommentTok{#> # A tibble: 6 x 5}
\CommentTok{#>   person test   post   pre  diff}
\CommentTok{#>   <chr>  <chr> <dbl> <dbl> <dbl>}
\CommentTok{#> 1 Greg   test1  81.0  74.0  7.00}
\CommentTok{#> 2 Greg   test2  80.0  71.0  9.00}
\CommentTok{#> 3 Sally  test1  80.0  70.0 10.0 }
\CommentTok{#> 4 Sally  test2  78.0  69.0  9.00}
\CommentTok{#> 5 Sue    test1  85.0  82.0  3.00}
\CommentTok{#> 6 Sue    test2  82.0  81.0  1.00}
\end{Highlighting}
\end{Shaded}

And it's similarly easy to plot:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(scores_}\DecValTok{3}\NormalTok{, }\KeywordTok{aes}\NormalTok{(person, diff, }\DataTypeTok{color =}\NormalTok{ test)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{size =} \DecValTok{2}\NormalTok{, }\DataTypeTok{colour =} \StringTok{"white"}\NormalTok{, }\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_path}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group =}\NormalTok{ person), }\DataTypeTok{colour =} \StringTok{"grey50"}\NormalTok{, }
    \DataTypeTok{arrow =} \KeywordTok{arrow}\NormalTok{(}\DataTypeTok{length =} \KeywordTok{unit}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\StringTok{"cm"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]
  \includegraphics[width=0.5\linewidth]{_figures/tidy_data/scores4-1}
\end{figure}

(Again, you'll learn about \texttt{mutate()} in the next chapter.)

\hypertarget{learning-more}{%
\section{Learning more}\label{learning-more}}

Data tidying is a big topic and this chapter only scratches the surface.
I recommend the following references which go into considerably more
depth on this topic:

\begin{itemize}
\item
  The tidyr documentation. I've described the most important arguments,
  but most functions have other arguments that help deal with less
  common situations. If you're struggling, make sure to read the
  documentation to see if there's an argument that might help you.
\item
  ``\href{http://www.jstatsoft.org/v59/i10/}{Tidy data}'', an article in
  the \emph{Journal of Statistical Software}. It describes the ideas of
  tidy data in more depth and shows other types of messy data.
  Unfortunately the paper was written before tidyr existed, so to see
  how to use tidyr instead of reshape2, consult the
  \href{http://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html}{tidyr
  vignette}.
\item
  The \href{http://rstudio.com/cheatsheets}{data wrangling cheatsheet}
  by RStudio, includes the most common tidyr verbs in a form designed to
  jog your memory when you're stuck.
\end{itemize}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-wickham:2007b}{}%
Wickham, Hadley. 2007. ``Reshaping Data with the Reshape Package.''
\emph{Journal of Statistical Software} 21 (12).
\url{http://www.jstatsoft.org/v21/i12/paper}.

\leavevmode\hypertarget{ref-tidy-data}{}%
---------. 2014. ``Tidy Data.'' \emph{The Journal of Statistical
Software} 59. \url{http://www.jstatsoft.org/v59/i10/}.
